{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tem5OMXKvS8n"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SX5pp4-D0SUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9JZ_9vlq0SXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
        "]\n",
        "pipe = pipeline(\"text-generation\", model=\"ISTA-DASLab/gemma-3-27b-it-GPTQ-4b-128g\", trust_remote_code=True)\n",
        "pipe(messages)"
      ],
      "metadata": {
        "id": "lTiPNTFp0Sar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/ISTA-DASLab/gemma-3-27b-it-GPTQ-4b-128g/blob/main/README.md"
      ],
      "metadata": {
        "id": "R7JPlysK05_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/huggingface/transformers@v4.49.0-Gemma-3"
      ],
      "metadata": {
        "id": "E1Gysvgs02m8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install compressed-tensors"
      ],
      "metadata": {
        "id": "exgWKTiv1X7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoProcessor, Gemma3ForConditionalGeneration\n",
        "from PIL import Image\n",
        "import requests\n",
        "import torch\n",
        "\n",
        "model_id = \"ISTA-DASLab/gemma-3-27b-it-GPTQ-4b-128g\"\n",
        "\n",
        "model = Gemma3ForConditionalGeneration.from_pretrained(\n",
        "    model_id, device_map=\"auto\"\n",
        ").eval()\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": [{\"type\": \"text\", \"text\": \"You are a helpful assistant.\"}]\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"image\", \"image\": \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/bee.jpg\"},\n",
        "            {\"type\": \"text\", \"text\": \"Describe this image in detail.\"}\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "inputs = processor.apply_chat_template(\n",
        "    messages, add_generation_prompt=True, tokenize=True,\n",
        "    return_dict=True, return_tensors=\"pt\"\n",
        ").to(model.device, dtype=torch.bfloat16)\n",
        "\n",
        "input_len = inputs[\"input_ids\"].shape[-1]\n",
        "\n",
        "with torch.inference_mode():\n",
        "    generation = model.generate(**inputs, max_new_tokens=5, do_sample=False)\n",
        "    generation = generation[0][input_len:]\n",
        "\n",
        "decoded = processor.decode(generation, skip_special_tokens=True)\n",
        "print(decoded)\n",
        "\n",
        "# **Overall Impression:** The image is a close-up shot of a vibrant garden scene,\n",
        "# focusing on a cluster of pink cosmos flowers and a busy bumblebee.\n",
        "# It has a slightly soft, natural feel, likely captured in daylight."
      ],
      "metadata": {
        "id": "sG7D5Peh0sx-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}